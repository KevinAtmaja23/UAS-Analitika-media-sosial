{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe34f1c8-b99e-4043-a273-850ba7e2a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "\n",
    "# from webdriver_manager.chrome import Chrome DriverManager\n",
    "driver = webdriver.Firefox()\n",
    "driver.get('https://twitter.com/login')\n",
    "\n",
    "# driver = webdriver. Chrome (Chrome DriverManager (). install())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a3e3d5-ef5e-4755-b661-0d348f4765cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "     ---------------------------------------- 0.0/250.0 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/250.0 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/250.0 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 30.7/250.0 kB 217.9 kB/s eta 0:00:02\n",
      "     ---- -------------------------------- 30.7/250.0 kB 217.9 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     ------ ------------------------------ 41.0/250.0 kB 195.7 kB/s eta 0:00:02\n",
      "     --------- ---------------------------- 61.4/250.0 kB 93.6 kB/s eta 0:00:03\n",
      "     --------- ---------------------------- 61.4/250.0 kB 93.6 kB/s eta 0:00:03\n",
      "     ---------- -------------------------- 71.7/250.0 kB 100.7 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 71.7/250.0 kB 100.7 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 71.7/250.0 kB 100.7 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 71.7/250.0 kB 100.7 kB/s eta 0:00:02\n",
      "     ---------- -------------------------- 71.7/250.0 kB 100.7 kB/s eta 0:00:02\n",
      "     -------------- ----------------------- 92.2/250.0 kB 97.1 kB/s eta 0:00:02\n",
      "     ------------------------- ---------- 174.1/250.0 kB 194.1 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 174.1/250.0 kB 194.1 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 225.3/250.0 kB 221.9 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 235.5/250.0 kB 228.7 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 235.5/250.0 kB 228.7 kB/s eta 0:00:01\n",
      "     ------------------------------------ 250.0/250.0 kB 225.5 kB/s eta 0:00:00\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d8b07dd-95ab-43a3-8a34-839cae245636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search item and fetch it\n",
    "search_box = driver.find_element(By.XPATH,\"//input[@data-testid='SearchBox_Search_Input']\")\n",
    "# search_box.send_keys (subject)\n",
    "search_box.send_keys(\"udinussemarang\")\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "UserTags=[]\n",
    "TimeStamps=[]\n",
    "Tweets=[]\n",
    "Replys=[]\n",
    "reTweets=[]\n",
    "Likes=[]\n",
    "Views=[]\n",
    "Sentimen=[]\n",
    "\n",
    "articles = driver.find_elements(By.XPATH,\"//article[@data-testid='tweet']\")\n",
    "\n",
    "while True:\n",
    "    for article in articles:\n",
    "        UserTag = article.find_element(By.XPATH,\".//span[contains(text(),'@')]\").text\n",
    "        UserTags.append(UserTag)\n",
    "\n",
    "        TimeStamp = article.find_element(By.XPATH,\".//time\").get_attribute('datetime')\n",
    "        TimeStamps.append(TimeStamp)\n",
    "        \n",
    "        Tweet = article.find_element(By.XPATH,\".//div[@data-testid='tweetText']\").text\n",
    "        Tweets.append(Tweet)\n",
    "        \n",
    "        Reply = article.find_element(By.XPATH,\".//div[@data-testid='reply']\").text\n",
    "        Replys.append(Reply)\n",
    "        \n",
    "        reTweet = article.find_element(By.XPATH,\".//div[@data-testid='retweet']\").text\n",
    "        reTweets.append(reTweet)\n",
    "        \n",
    "        Like = article.find_element(By.XPATH,\".//div[@data-testid='like']\").text\n",
    "        Likes.append(Like)\n",
    "\n",
    "        sid_obj= Sentiment IntensityAnalyzer()\n",
    "        sentiment_dict = sid_obj.polarity_scores(Tweet)\n",
    "            if sentiment_dict['compound'] >= 0.05 :\n",
    "        value=\"1.0\"\n",
    "            elif sentiment_dict['compound'] <= -0.05 :\n",
    "        value=\"-1.0\"\n",
    "        else :\n",
    "            value = \"0.0\"\n",
    "        Sentimen.append(value)\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    sleep(3)\n",
    "    articles = driver.find_elements(By.XPATH,\"//article[@data-testid='tweet']\")\n",
    "    Tweets2 = list(set(Tweets))\n",
    "    if len(Tweets2) > 5:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab26b428-14c1-4412-873a-40f43aef699e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame(zip(UserTags,TimeStamps,Tweets,Replys,reTweets,Likes)\n",
    "                   ,columns=['UserTags','TimeStamps','Tweets','Replys','reTweets','Likes'])\n",
    "\n",
    "df.to_excel(\"D:\\\\tweets_live.xlsx\",index=False)\n",
    "\n",
    "sleep(3)\n",
    "import os\n",
    "os.system('start \"excel\" \"D:\\\\tweets_live.xlsx\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ef501-eef9-45d7-866e-72cd8e63f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "text_processor = TextPreProcessor(\n",
    "\n",
    "        normalize=['email', 'percent', 'money', 'phone', 'user','time', 'date', 'number'],\n",
    "            ,→'censored'},\n",
    "        annotate={\"hashtag\"},\n",
    "\n",
    "        fix_html=True, \n",
    "            segmenter=\"twitter\",\n",
    "\n",
    "        corrector=\"twitter\",\n",
    "            unpack_hashtags=True, \n",
    "            unpack_contractions=True, \n",
    "            spell_correct_elong=False, \n",
    "            tokenizer=SocialTokenizer(lowercase=True).tokenize\n",
    "            dicts=[emoticons]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39858008-e0d3-417e-bc53-9db253c5f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def bersih_data(text):\n",
    "        return \" \".join(text_processor.pre_process_doc(text))\n",
    "    def non_ascii(text):\n",
    "        return text.encode('ascii', 'replace').decode('ascii')\n",
    "    def remove_space_alzami(text):\n",
    "        return \" \".join(text.split())\n",
    "    def remove_emoji_alzami(text):\n",
    "        return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\",\" \", text).split())\n",
    "    def remove_tab(text):\n",
    "        return text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").\n",
    "        ,→replace('\\\\',\"\")\n",
    "    def remove_tab2(text):\n",
    "        return re.sub('\\s+',' ',text)\n",
    "    def remove_rt(text):\n",
    "        return text.replace('RT',\" \")\n",
    "    def remove_mention(text):\n",
    "        return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    def remove_incomplete_url(text):\n",
    "        return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "    def remove_single_char(text):\n",
    "        return re.sub(r\"\\b[a-zA-Z]\\b\", \"\",text)\n",
    "    def remove_excessive_dot(text):\n",
    "        return text.replace('..',\" \")\n",
    "    def change_stripe(text):\n",
    "        return text.replace('-',\" \")\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    def remove_single_char(text):\n",
    "        return re.sub(r\"\\b[a-zA-Z]\\b\", \"\",text)\n",
    "    def remove_excessive_dot(text):\n",
    "        return text.replace('..',\" \")\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    def remove_whitespace_LT(text):\n",
    "        return text.strip()\n",
    "    def remove_whitespace_multiple(text):\n",
    "        return re.sub('\\s+',' ',text)\n",
    "    def remove_punctuation(text):\n",
    "        remove = string.punctuation\n",
    "        remove = remove.replace(\"_\", \"\")\n",
    "\n",
    "    pattern = r\"[{}]\".format(remove) \n",
    "    return re.sub(pattern, \"\", text)\n",
    "\n",
    "    def remove_number_eks(text):\n",
    "        return text.replace('<number>',\" \")\n",
    "    def remove_angka(text):\n",
    "        return re.sub(r\"\\d+\", \"\", text)\n",
    "    def remove_URL_eks(text):\n",
    "        return text.replace('URL',\" \").replace('url',\" \")\n",
    "    def space_punctuation(text):\n",
    "        return re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2fbcb-b150-476b-97df-4619f07cc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    i = 0\n",
    "    final_string = []\n",
    "    s = \"\"\n",
    "        for text in df['Tweet'].values:\n",
    "        filteredSentence = []\n",
    "        EachReviewText = \"\"\n",
    "            proc = remove_rt(text)\n",
    "            proc = lower(proc)\n",
    "            proc = change_stripe(proc)\n",
    "            proc = remove_emoji_alzami(proc)\n",
    "            proc = remove_tab(proc)\n",
    "            proc = remove_tab2(proc)\n",
    "            proc = non_ascii(proc)\n",
    "            proc = remove_incomplete_url(proc)\n",
    "            proc = remove_excessive_dot(proc)\n",
    "            proc = remove_whitespace_LT(proc)\n",
    "            proc = remove_whitespace_multiple(proc)\n",
    "            proc = remove_single_char(proc)\n",
    "            proc = space_punctuation(proc)\n",
    "            proc = remove_punctuation(proc)\n",
    "            proc = remove_space_alzami(proc)\n",
    "            proc = bersih_data(proc)\n",
    "            proc = remove_number_eks(proc)\n",
    "            proc = remove_angka(proc)\n",
    "            proc = remove_URL_eks(proc)\n",
    "        EachReviewText = proc\n",
    "        final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9dd6d-91f1-4bca-9355-f30a41f8fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    : df[\"step01\"] = final_string\n",
    "     df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c9292-61f7-4f90-bf8f-935b48008ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_hapus = df[~df['step01'].str.contains(\" \")]\n",
    "    df_new = df[~df.isin(df_hapus)].dropna()\n",
    "    df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62173d-d214-4b65-b3d4-0119e8b3924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "    df_new['tokens'] = df['step01'].apply(word_tokenize_wrapper)\n",
    "\n",
    "    df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c15a21f-d35e-4bac-ae7e-1d39c2b98d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "   normalized_word = pd.read_csv('kamus_alzami_clean.csv', sep=\",\")\n",
    "        normalized_word_dict = {}\n",
    "\n",
    "            for index, row in normalized_word.iterrows():\n",
    "        if row[0] not in normalized_word_dict:\n",
    "            normalized_word_dict[row[0]] = row[1]\n",
    "            \n",
    "        def normalized_term(document):\n",
    "        return [normalized_word_dict[term] if term in normalized_word_dict else term␣\n",
    "        ,→for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271ec68-5309-45a0-9406-f4acfd15f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_new['final_tokens'] = df_new['tokens'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c395b9-6a34-4fe1-a5b8-b58e914eb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    i=0\n",
    "        final_string_tokens = []\n",
    "        for text in df_new['final_tokens'].values:\n",
    "            \n",
    "    EachReviewText = \"\"\n",
    "        EachReviewText = ' '.join(text)\n",
    "    final_string_tokens.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31daf4b-caf2-4b3f-9dce-4412f8b260d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"step02\"] = final_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100af52-f1a8-4370-82e8-0c0c9f4cfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb8fad-bce6-47dd-bf57-1a36b525319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('clean_dataset_part01.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df11806-8447-485c-b5a8-e2ee0adee34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4540e2e-0906-4c5b-94fe-f0ad3b7aa8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import␣,→StopWordRemoverFactory\n",
    "    factory = StopWordRemoverFactory()\n",
    "    more_stopword = ['sih', 'nya','rt','loh','lah', 'dd', 'mah', 'nye', 'eh', 'ehh',␣,→'ah', 'yang']\n",
    "\n",
    "    data = factory.get_stop_words()+more_stopword\n",
    "        stopwords_sastrawi = factory.create_stop_word_remover()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cede8b6-037d-4fa9-a757-108a647bcb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['step02'] = df_new['step02'].apply(str)\n",
    "    df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93c46e-fa60-4878-ad59-6d14969bc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "    final_string = []\n",
    "    s = \"\"\n",
    "        for sentence in df_new[\"step02\"].values:\n",
    "            filteredSentence = []\n",
    "        EachReviewText = \"\"\n",
    "            st = stopwords_sastrawi.remove(sentence)\n",
    "            s = (stemmer.stem(st))\n",
    "        filteredSentence.append(s)\n",
    "            EachReviewText = ' '.join(filteredSentence)\n",
    "        final_string.append(EachReviewText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b39023-f8d5-4807-8659-4c53c980ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[:, ('ProcessedText')] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4141f2-6f74-44c5-82bc-2c2143ba3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705d06c-93dc-41a1-8e4d-1cadd4f730b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1781d-5913-4827-81f6-f9deae9d3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('clean_dataset_uts_part02.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d96b9ac-c109-4077-95c1-3124272cfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_feature = dataset['ProcessedText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcdc29-06f7-4fbc-8587-1ad41d27c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97046b5c-f873-44bc-ba3a-781fd7fa49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80368b-4a55-4bd0-b08a-5d00b913b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448484c-4f48-44b8-8bbc-be8489f85177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8bd89-d2db-4392-8e37-5d731a53535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517ef75-20fd-4301-828b-5912fb9c9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d9744-2f68-43be-8bbf-288f49f856d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94006ae3-0ae8-4c17-8469-ae317b4b138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53e46c-5b0c-45aa-ac2a-1dd3dead8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_label, test_label = train_test_split(dataset_feature,␣,→dataset_label, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f3eac-2d5d-4e3c-8325-44e48f216b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb44274-c5b0-4254-ac37-b18577ebe544",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_Vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea40397-2fbf-4237-b072-2762bc30240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    " from sklearn.pipeline import Pipeline\n",
    "    classifier_nb = Pipeline([\n",
    "       ('tfidf', TfidfVectorizer()),\n",
    "        ('model', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1b3f5-27b3-4d90-8e25-6d3e234dc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_nb = {\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "        #'tfidf__use_idf': (True, False),\n",
    "        'model__alpha': (0, 1, 1e-2, 1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f1394-dde6-40e0-9e36-05dfcf8c3975",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nb = GridSearchCV(classifier_nb, parameters_nb, cv = 3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96f76c-b8ec-4533-84fd-e93116b01e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nb.fit(train_x, train_label.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656d465-14ca-4cdd-884e-1795c85cc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(cv=3,\n",
    "        estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
    "        ('model', MultinomialNB())]),\n",
    "    n_jobs=-1,\n",
    "             \n",
    "        param_grid={'model__alpha': (0, 1, 0.01, 0.001),'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3),(1, 4)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57366da7-32d6-4765-8e49-7fc4ed16b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb_train = classifier_nb.predict(train_x)\n",
    "        accuracy_nb_train = accuracy_score(train_label, y_pred_nb_train)\n",
    "    print(\"Accuracy Training set: \", accuracy_nb_train)\n",
    "        y_pred_nb_test = classifier_nb.predict(test_x)\n",
    "    accuracy_nb_test = accuracy_score(test_label, y_pred_nb_test)\n",
    "print(\"Accuracy Test set: \", accuracy_nb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca9493-62d0-44af-9c7a-2bb5be913687",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb_train = classifier_nb.predict(train_x)\n",
    "        accuracy_nb_train = accuracy_score(train_label, y_pred_nb_train)\n",
    "print(\"Accuracy Training set: \", accuracy_nb_train)\n",
    "        y_pred_nb_test = classifier_nb.predict(test_x)\n",
    "        accuracy_nb_test = accuracy_score(test_label, y_pred_nb_test)\n",
    "print(\"Accuracy Test set: \", accuracy_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e42fa8-69e5-4dfc-91cf-976a634bb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_nb_train = recall_score(train_label, y_pred_nb_train, average='weighted')\n",
    "    print(\"Recall Training set: \", recall_nb_train)\n",
    "recall_nb_test = recall_score(test_label, y_pred_nb_test, average='weighted')\n",
    "    print(\"Recall Test set: \", recall_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bfb173-6076-4516-b093-fcc850e063fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_nb_train = precision_score(train_label, y_pred_nb_train,␣,→average='weighted')\n",
    "    print(\"Precision Training set: \", precision_nb_train)\n",
    "precision_nb_test = precision_score(test_label, y_pred_nb_test,␣,→average='weighted')\n",
    "    print(\"Precision Test set: \", precision_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abda0dd9-0313-4335-aa2e-477d1dbc26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_nb_train = f1_score(train_label, y_pred_nb_train, average='weighted')\n",
    "    print(\"F1 Training set: \", f1_nb_train)\n",
    "f1_nb_test = f1_score(test_label, y_pred_nb_test, average='weighted')\n",
    "    print(\"F1 Test set: \", f1_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478f456-5294-453d-9787-8e79f99f22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "    sns.heatmap(confusion_matrix(test_label, y_pred_nb_test), annot=True, cmap =␣\n",
    "    ,→'viridis', fmt='.0f')\n",
    "plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.ylabel(\"Actual values\" , fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0caf90-2f97-4871-888d-f5763f5f16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53428fd6-9eb1-4a50-8078-5964bff7b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
    "('model', MultinomialNB(alpha=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305c33d-8c03-465c-ad1f-9e9c40e5fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name in sorted(parameters_nb.keys()):\n",
    "print(\"%s: %r\" % (param_name, classifier_nb.best_params_[param_name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
